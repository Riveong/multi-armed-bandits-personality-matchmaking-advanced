{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8055577,"sourceType":"datasetVersion","datasetId":4751114}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T20:06:31.189632Z","iopub.execute_input":"2024-04-21T20:06:31.190126Z","iopub.status.idle":"2024-04-21T20:06:31.200539Z","shell.execute_reply.started":"2024-04-21T20:06:31.190093Z","shell.execute_reply":"2024-04-21T20:06:31.199053Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"/kaggle/input/preprocessed/preprocessed_data.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"![Multi Armed](https://media.discordapp.net/attachments/1023598916857499680/1228695121919344700/Desktop_-_4.png?ex=662cfa81&is=661a8581&hm=d0a7cd731cb0afdc3d67238dd26e876fac0f0e39a2b82ebe98b71f5e12630f96&=&format=webp&quality=lossless&width=1440&height=442)","metadata":{}},{"cell_type":"markdown","source":"Dataset link :<br>\nCode by :","metadata":{}},{"cell_type":"markdown","source":"# Data Overview","metadata":{}},{"cell_type":"code","source":"predf = pd.read_csv('/kaggle/input/preprocessed/preprocessed_data.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:31.202564Z","iopub.execute_input":"2024-04-21T20:06:31.202919Z","iopub.status.idle":"2024-04-21T20:06:31.826798Z","shell.execute_reply.started":"2024-04-21T20:06:31.202891Z","shell.execute_reply":"2024-04-21T20:06:31.825390Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"predf","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:31.828676Z","iopub.execute_input":"2024-04-21T20:06:31.829015Z","iopub.status.idle":"2024-04-21T20:06:31.845570Z","shell.execute_reply.started":"2024-04-21T20:06:31.828988Z","shell.execute_reply":"2024-04-21T20:06:31.844163Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"        Unnamed: 0  user_id  match_id  similarity_score  response\n0                0        0         0          1.000000         1\n1                1        1         0         -0.932901         0\n2                2        2         0          0.991195         1\n3                3        3         0          0.853614         1\n4                4        4         0         -0.188426         0\n...            ...      ...       ...               ...       ...\n806399      806399      893       897         -0.997454         0\n806400      806400      894       897         -0.165053         0\n806401      806401      895       897          0.291728         0\n806402      806402      896       897         -0.095429         0\n806403      806403      897       897          1.000000         1\n\n[806404 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>user_id</th>\n      <th>match_id</th>\n      <th>similarity_score</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.932901</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.991195</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.853614</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n      <td>-0.188426</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>806399</th>\n      <td>806399</td>\n      <td>893</td>\n      <td>897</td>\n      <td>-0.997454</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806400</th>\n      <td>806400</td>\n      <td>894</td>\n      <td>897</td>\n      <td>-0.165053</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806401</th>\n      <td>806401</td>\n      <td>895</td>\n      <td>897</td>\n      <td>0.291728</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806402</th>\n      <td>806402</td>\n      <td>896</td>\n      <td>897</td>\n      <td>-0.095429</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806403</th>\n      <td>806403</td>\n      <td>897</td>\n      <td>897</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>806404 rows Ã— 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predf.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:31.847227Z","iopub.execute_input":"2024-04-21T20:06:31.847683Z","iopub.status.idle":"2024-04-21T20:06:31.860853Z","shell.execute_reply.started":"2024-04-21T20:06:31.847641Z","shell.execute_reply":"2024-04-21T20:06:31.859504Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"predf=predf.drop(['Unnamed: 0'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:31.864839Z","iopub.execute_input":"2024-04-21T20:06:31.865384Z","iopub.status.idle":"2024-04-21T20:06:31.879815Z","shell.execute_reply.started":"2024-04-21T20:06:31.865340Z","shell.execute_reply":"2024-04-21T20:06:31.878422Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"predf","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:31.881170Z","iopub.execute_input":"2024-04-21T20:06:31.881946Z","iopub.status.idle":"2024-04-21T20:06:31.898936Z","shell.execute_reply.started":"2024-04-21T20:06:31.881893Z","shell.execute_reply":"2024-04-21T20:06:31.897403Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"        user_id  match_id  similarity_score  response\n0             0         0          1.000000         1\n1             1         0         -0.932901         0\n2             2         0          0.991195         1\n3             3         0          0.853614         1\n4             4         0         -0.188426         0\n...         ...       ...               ...       ...\n806399      893       897         -0.997454         0\n806400      894       897         -0.165053         0\n806401      895       897          0.291728         0\n806402      896       897         -0.095429         0\n806403      897       897          1.000000         1\n\n[806404 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>match_id</th>\n      <th>similarity_score</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.932901</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0.991195</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0.853614</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>-0.188426</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>806399</th>\n      <td>893</td>\n      <td>897</td>\n      <td>-0.997454</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806400</th>\n      <td>894</td>\n      <td>897</td>\n      <td>-0.165053</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806401</th>\n      <td>895</td>\n      <td>897</td>\n      <td>0.291728</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806402</th>\n      <td>896</td>\n      <td>897</td>\n      <td>-0.095429</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>806403</th>\n      <td>897</td>\n      <td>897</td>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>806404 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import random","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:31.900412Z","iopub.execute_input":"2024-04-21T20:06:31.900887Z","iopub.status.idle":"2024-04-21T20:06:31.908198Z","shell.execute_reply.started":"2024-04-21T20:06:31.900846Z","shell.execute_reply":"2024-04-21T20:06:31.906583Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# Recommender\nLearning Policy:  \n- Greedy (epsilon)\n- Linear Greedy\n- Linear Greedy (with epsilon)\n- Thompson Sampling\n\nUsage Guide:  \nnum arm = num of items  \nnum rounds = num of iteration","metadata":{}},{"cell_type":"markdown","source":"## Greedy\n","metadata":{}},{"cell_type":"code","source":"def epsilon_greedy_bandit(dataset, num_arms, epsilon, num_rounds):\n    estimated_rewards = [0] * num_arms\n    num_selected = [0] * num_arms\n    total_rewards = 0\n    exploration_count = 0\n    exploitation_count = 0\n\n    for _ in range(num_rounds):\n        if random.random() < epsilon:\n            # Explore: Choose a random arm\n            chosen_arm = random.randint(0, num_arms - 1)\n            exploration_count += 1\n        else:\n            # Exploit: Choose the arm with the highest estimated reward\n            chosen_arm = max(range(num_arms), key=lambda arm: estimated_rewards[arm])\n            exploitation_count += 1\n\n        # Randomly select an observation for the chosen arm from the dataset\n        chosen_row = dataset[dataset['match_id'] == chosen_arm].sample(n=1)\n        \n        # Observe the reward (response) for the chosen arm\n        reward = chosen_row['response'].values[0]\n        total_rewards += reward\n\n        # Update the estimated reward for the chosen arm\n        num_selected[chosen_arm] += 1\n        estimated_rewards[chosen_arm] += (reward - estimated_rewards[chosen_arm]) / num_selected[chosen_arm]\n\n    return estimated_rewards, num_selected, exploration_count, exploitation_count, total_rewards","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:31.910267Z","iopub.execute_input":"2024-04-21T20:06:31.910809Z","iopub.status.idle":"2024-04-21T20:06:31.922950Z","shell.execute_reply.started":"2024-04-21T20:06:31.910772Z","shell.execute_reply":"2024-04-21T20:06:31.921178Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"results = epsilon_greedy_bandit(predf, num_arms=100, epsilon=0.5, num_rounds=100)\nprint(\"Estimated rewards for each arm:\", results[0])\nprint(\"Number of times each arm was selected:\", results[1])\nprint(\"Exploration count:\", results[2])\nprint(\"Exploitation count:\", results[3])\nprint(\"Total rewards:\", results[4])","metadata":{"_kg_hide-input":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-04-21T20:06:31.925328Z","iopub.execute_input":"2024-04-21T20:06:31.925864Z","iopub.status.idle":"2024-04-21T20:06:32.080731Z","shell.execute_reply.started":"2024-04-21T20:06:31.925821Z","shell.execute_reply":"2024-04-21T20:06:32.079183Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Estimated rewards for each arm: [0.6, 0.5, 0, 0, 0.0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0.0, 0, 0.6, 0, 0, 0, 0.0, 0, 0, 0, 0.0, 0, 0.0, 0.5, 0, 0, 0, 0.5, 0, 0, 0.0, 0.5000000000000001, 0, 0, 0, 0.0, 0, 0.0, 0, 0.5, 0, 0.0, 0, 0.5714285714285715, 0.5, 0, 0, 0.5, 0.0, 0.0, 0, 0.0, 0.0, 0, 0, 0.0, 0.33333333333333337, 0.5, 0.0, 0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0, 0, 0.5, 0.5, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0.0]\nNumber of times each arm was selected: [15, 6, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 5, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 1, 8, 0, 0, 0, 1, 0, 1, 0, 4, 0, 2, 0, 7, 2, 0, 0, 2, 1, 1, 0, 1, 2, 0, 0, 1, 3, 4, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 1]\nExploration count: 53\nExploitation count: 47\nTotal rewards: 37\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Thompson Sampling","metadata":{}},{"cell_type":"code","source":"def thompson_sampling_bandit(dataset, num_arms, num_rounds):\n    # Parameters for the Beta distribution of each arm: successes (alpha) and failures (beta)\n    alpha = np.ones(num_arms)\n    beta = np.ones(num_arms)\n    \n    total_rewards = 0\n\n    # Iterate through the specified number of rounds\n    for _ in range(num_rounds):\n        # Sample from the Beta distribution for each arm\n        theta = [np.random.beta(alpha[i] + 1, beta[i] + 1) for i in range(num_arms)]\n        \n        # Choose the arm with the highest sampled probability\n        chosen_arm = np.argmax(theta)\n\n        # Randomly select an observation for the chosen arm from the dataset\n        # Here, filtering dataset where 'match_id' equals chosen_arm and sampling one row\n        chosen_row = dataset[dataset['match_id'] == chosen_arm].sample(n=1)\n        \n        # Observe the reward (response) for the chosen arm\n        reward = chosen_row['response'].values[0]\n        total_rewards += reward\n        \n        # Update the alpha and beta for the chosen arm based on the reward\n        if reward > 0:\n            alpha[chosen_arm] += 1\n        else:\n            beta[chosen_arm] += 1\n\n    return alpha, beta, total_rewards","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:32.082519Z","iopub.execute_input":"2024-04-21T20:06:32.082959Z","iopub.status.idle":"2024-04-21T20:06:32.093639Z","shell.execute_reply.started":"2024-04-21T20:06:32.082924Z","shell.execute_reply":"2024-04-21T20:06:32.091876Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"num_arms = 100 # Number of items\nnum_rounds = 100  # Number of interactions\nresults = thompson_sampling_bandit(predf, num_arms, num_rounds)\nprint(\"Updated alpha and beta parameters:\", results[0:2])\nprint(\"Total rewards accumulated:\", results[2])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:32.098584Z","iopub.execute_input":"2024-04-21T20:06:32.099004Z","iopub.status.idle":"2024-04-21T20:06:32.297196Z","shell.execute_reply.started":"2024-04-21T20:06:32.098972Z","shell.execute_reply":"2024-04-21T20:06:32.295902Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Updated alpha and beta parameters: (array([1., 2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 3., 2., 1., 2., 1.,\n       1., 1., 1., 1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 1., 3., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 3., 1., 1., 1., 1., 3., 1., 1., 1.,\n       2., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 2., 1., 1., 1., 2., 1., 1., 3., 1., 2., 2., 3., 3., 1.,\n       2., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 2.]), array([1., 2., 1., 2., 2., 1., 1., 1., 2., 1., 2., 1., 2., 3., 1., 2., 1.,\n       1., 1., 2., 2., 1., 2., 2., 2., 2., 1., 2., 2., 2., 2., 2., 1., 1.,\n       1., 2., 2., 2., 2., 2., 1., 2., 1., 1., 2., 2., 2., 2., 1., 2., 1.,\n       1., 2., 2., 2., 2., 2., 1., 1., 2., 1., 1., 2., 1., 2., 2., 2., 2.,\n       1., 2., 1., 2., 2., 2., 3., 2., 2., 1., 2., 2., 2., 2., 2., 1., 2.,\n       1., 3., 2., 2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2.]))\nTotal rewards accumulated: 30\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Linear Greedy","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\ndef linear_greedy_bandit(dataset, num_arms, num_rounds):\n    model = LinearRegression()\n    total_rewards = 0\n    chosen_arms = []\n    \n    # Initialize the dataset for training the model\n    # Start with one example for each arm if possible\n    training_data = pd.DataFrame()\n    for arm in range(num_arms):\n        if dataset[dataset['match_id'] == arm].shape[0] > 0:\n            # Append the first instance for each arm to the training data\n            # Use concat instead of append\n            training_data = pd.concat([training_data, dataset[dataset['match_id'] == arm].iloc[:1]], ignore_index=True)\n\n    # Check if there are any entries in the training data before fitting\n    if not training_data.empty:\n        # Training the model on initial data\n        model.fit(training_data[['similarity_score']], training_data['response'])\n\n        for _ in range(num_rounds):\n            predictions = model.predict(dataset[['similarity_score']])\n            dataset['predicted_reward'] = predictions\n\n            # Choose the arm with the highest predicted reward\n            max_indices = dataset.groupby('match_id')['predicted_reward'].idxmax()\n            chosen_arm = dataset.loc[max_indices].sample(n=1)\n            chosen_arm_index = chosen_arm.index.item()\n\n            # Observe the reward\n            reward = dataset.at[chosen_arm_index, 'response']\n            total_rewards += reward\n            chosen_arms.append(chosen_arm['match_id'].values[0])\n            \n            # Add this data point to the training dataset\n            training_data = pd.concat([training_data, dataset.loc[chosen_arm_index:chosen_arm_index]], ignore_index=True)\n\n            # Re-train the model with updated data\n            model.fit(training_data[['similarity_score']], training_data['response'])\n\n    return chosen_arms, total_rewards\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:32.299028Z","iopub.execute_input":"2024-04-21T20:06:32.299523Z","iopub.status.idle":"2024-04-21T20:06:32.313134Z","shell.execute_reply.started":"2024-04-21T20:06:32.299475Z","shell.execute_reply":"2024-04-21T20:06:32.311695Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"## linear greedy with exploration (epsilon)","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nimport random\nimport pandas as pd\n\ndef linear_greedy_bandit_epsilon(dataset, num_arms, epsilon, num_rounds):\n    model = LinearRegression()\n    total_rewards = 0\n    chosen_arms = []\n    \n    # Initialize the dataset for training the model\n    training_data = pd.DataFrame()\n    for arm in range(num_arms):\n        # Attempt to start with one example for each arm\n        arm_data = dataset[dataset['match_id'] == arm]\n        if not arm_data.empty:\n            training_data = pd.concat([training_data, arm_data.iloc[:1]], ignore_index=True)\n\n    # Training the model on initial data if available\n    if not training_data.empty:\n        model.fit(training_data[['similarity_score']], training_data['response'])\n\n        for _ in range(num_rounds):\n            # Exploration vs. Exploitation\n            if random.random() < epsilon:\n                # Explore: Randomly select an arm\n                chosen_arm_index = dataset.sample(n=1).index.item()\n            else:\n                # Exploit: Select the arm with the highest predicted reward\n                predictions = model.predict(dataset[['similarity_score']])\n                dataset.loc[:, 'predicted_reward'] = predictions\n                max_indices = dataset.groupby('match_id')['predicted_reward'].idxmax()\n                chosen_arm_index = dataset.loc[max_indices].sample(n=1).index.item()\n            \n            # Observe the reward and the chosen arm\n            reward = dataset.at[chosen_arm_index, 'response']\n            total_rewards += reward\n            chosen_arm = dataset.at[chosen_arm_index, 'match_id']\n            chosen_arms.append(chosen_arm)\n            \n            # Add this data point to the training dataset\n            training_data = pd.concat([training_data, dataset.loc[chosen_arm_index:chosen_arm_index]], ignore_index=True)\n            \n            # Re-train the model with the updated training data\n            model.fit(training_data[['similarity_score']], training_data['response'])\n\n    return chosen_arms, total_rewards\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:32.315238Z","iopub.execute_input":"2024-04-21T20:06:32.315679Z","iopub.status.idle":"2024-04-21T20:06:32.332012Z","shell.execute_reply.started":"2024-04-21T20:06:32.315642Z","shell.execute_reply":"2024-04-21T20:06:32.330602Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"linear greedy output","metadata":{}},{"cell_type":"code","source":"results = linear_greedy_bandit(predf, num_arms=8, num_rounds=100)\nprint(\"Chosen arms per round:\", results[0])\nprint(\"Total rewards accumulated:\", results[1])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:32.333843Z","iopub.execute_input":"2024-04-21T20:06:32.334220Z","iopub.status.idle":"2024-04-21T20:06:35.424215Z","shell.execute_reply.started":"2024-04-21T20:06:32.334191Z","shell.execute_reply":"2024-04-21T20:06:35.423144Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Chosen arms per round: [384, 135, 670, 597, 334, 137, 436, 326, 458, 621, 75, 13, 479, 107, 63, 848, 334, 440, 817, 775, 261, 90, 466, 389, 872, 826, 657, 56, 347, 767, 666, 773, 706, 92, 785, 449, 248, 633, 395, 223, 374, 197, 203, 124, 681, 894, 206, 434, 847, 732, 180, 380, 259, 700, 832, 237, 478, 424, 213, 205, 122, 401, 427, 543, 18, 834, 607, 190, 680, 538, 544, 449, 469, 514, 873, 251, 193, 269, 69, 731, 151, 369, 606, 452, 646, 305, 784, 197, 272, 696, 626, 816, 816, 787, 421, 343, 784, 640, 250, 396]\nTotal rewards accumulated: 100\n","output_type":"stream"}]},{"cell_type":"markdown","source":"linear greedy with epsilon","metadata":{}},{"cell_type":"code","source":"results = linear_greedy_bandit_epsilon(predf, num_arms=8,epsilon=0.5, num_rounds=100)\nprint(\"Chosen arms per round:\", results[0])\nprint(\"Total rewards accumulated:\", results[1])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:35.425534Z","iopub.execute_input":"2024-04-21T20:06:35.425880Z","iopub.status.idle":"2024-04-21T20:06:38.469777Z","shell.execute_reply.started":"2024-04-21T20:06:35.425853Z","shell.execute_reply":"2024-04-21T20:06:38.468567Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Chosen arms per round: [301, 334, 884, 49, 314, 885, 121, 807, 489, 683, 69, 411, 554, 295, 601, 732, 631, 101, 134, 503, 573, 722, 768, 716, 372, 702, 102, 887, 382, 340, 319, 630, 721, 282, 660, 304, 739, 630, 223, 54, 149, 290, 317, 726, 670, 476, 284, 696, 713, 868, 269, 58, 213, 195, 784, 226, 732, 490, 102, 74, 360, 835, 642, 477, 163, 544, 23, 537, 259, 111, 890, 116, 601, 126, 783, 324, 756, 222, 135, 98, 575, 682, 844, 342, 275, 145, 215, 897, 235, 338, 56, 354, 241, 524, 537, 786, 785, 148, 225, 400]\nTotal rewards accumulated: 65\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:38.471026Z","iopub.execute_input":"2024-04-21T20:06:38.471416Z","iopub.status.idle":"2024-04-21T20:06:38.477211Z","shell.execute_reply.started":"2024-04-21T20:06:38.471387Z","shell.execute_reply":"2024-04-21T20:06:38.475993Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"# Simulation, Validation & Benchmarking","metadata":{}},{"cell_type":"markdown","source":"specific user for matchmaking","metadata":{}},{"cell_type":"code","source":"user_id = 2\nuser_data = predf[predf['user_id'] == user_id]\nnum_arms = user_data['match_id'].nunique()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:38.478532Z","iopub.execute_input":"2024-04-21T20:06:38.478883Z","iopub.status.idle":"2024-04-21T20:06:38.489362Z","shell.execute_reply.started":"2024-04-21T20:06:38.478854Z","shell.execute_reply":"2024-04-21T20:06:38.488121Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"user_data","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:38.491248Z","iopub.execute_input":"2024-04-21T20:06:38.491740Z","iopub.status.idle":"2024-04-21T20:06:38.507929Z","shell.execute_reply.started":"2024-04-21T20:06:38.491703Z","shell.execute_reply":"2024-04-21T20:06:38.506941Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"        user_id  match_id  similarity_score  response  predicted_reward\n2             2         0          0.991195         1          0.978799\n900           2         1         -0.972371         0         -0.155211\n1798          2         2          1.000000         1          0.983884\n2696          2         3          0.777127         1          0.855169\n3594          2         4         -0.056732         0          0.373594\n...         ...       ...               ...       ...               ...\n801916        2       893          0.979640         1          0.972125\n802814        2       894          0.292241         0          0.575135\n803712        2       895         -0.413951         0          0.167291\n804610        2       896          0.224405         0          0.535958\n805508        2       897         -0.991463         0         -0.166237\n\n[898 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>match_id</th>\n      <th>similarity_score</th>\n      <th>response</th>\n      <th>predicted_reward</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0.991195</td>\n      <td>1</td>\n      <td>0.978799</td>\n    </tr>\n    <tr>\n      <th>900</th>\n      <td>2</td>\n      <td>1</td>\n      <td>-0.972371</td>\n      <td>0</td>\n      <td>-0.155211</td>\n    </tr>\n    <tr>\n      <th>1798</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0.983884</td>\n    </tr>\n    <tr>\n      <th>2696</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0.777127</td>\n      <td>1</td>\n      <td>0.855169</td>\n    </tr>\n    <tr>\n      <th>3594</th>\n      <td>2</td>\n      <td>4</td>\n      <td>-0.056732</td>\n      <td>0</td>\n      <td>0.373594</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>801916</th>\n      <td>2</td>\n      <td>893</td>\n      <td>0.979640</td>\n      <td>1</td>\n      <td>0.972125</td>\n    </tr>\n    <tr>\n      <th>802814</th>\n      <td>2</td>\n      <td>894</td>\n      <td>0.292241</td>\n      <td>0</td>\n      <td>0.575135</td>\n    </tr>\n    <tr>\n      <th>803712</th>\n      <td>2</td>\n      <td>895</td>\n      <td>-0.413951</td>\n      <td>0</td>\n      <td>0.167291</td>\n    </tr>\n    <tr>\n      <th>804610</th>\n      <td>2</td>\n      <td>896</td>\n      <td>0.224405</td>\n      <td>0</td>\n      <td>0.535958</td>\n    </tr>\n    <tr>\n      <th>805508</th>\n      <td>2</td>\n      <td>897</td>\n      <td>-0.991463</td>\n      <td>0</td>\n      <td>-0.166237</td>\n    </tr>\n  </tbody>\n</table>\n<p>898 rows Ã— 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Simulation: Matchmaking (user based)","metadata":{}},{"cell_type":"markdown","source":"simulation e greedy","metadata":{}},{"cell_type":"code","source":"def epsilon_greedy_matchmaking(user_id, user_data, num_arms, epsilon, num_rounds):\n    estimated_rewards = [0] * num_arms\n    num_selected = [0] * num_arms\n    total_reward = 0\n    selected_arms = []\n\n    for _ in range(num_rounds):\n        if random.random() < epsilon:\n            # Explore\n            chosen_arm = random.choice(user_data['match_id'].unique())\n        else:\n            # Exploit\n            chosen_arm = max(range(num_arms), key=lambda arm: estimated_rewards[arm])\n\n        # Simulate getting a reward for the chosen arm from the user interactions\n        reward_row = user_data[(user_data['user_id'] == user_id) & (user_data['match_id'] == chosen_arm)].sample()\n        reward = reward_row['response'].values[0]\n        total_reward += reward\n\n        # Update the estimated rewards and number of times each arm was selected\n        arm_index = list(user_data['match_id'].unique()).index(chosen_arm)\n        num_selected[arm_index] += 1\n        estimated_rewards[arm_index] += (reward - estimated_rewards[arm_index]) / num_selected[arm_index]\n\n        # If the reward is 1, add the arm to the list of selected arms\n        if reward == 1:\n            selected_arms.append(chosen_arm)\n\n    return selected_arms, total_reward","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:38.509044Z","iopub.execute_input":"2024-04-21T20:06:38.509990Z","iopub.status.idle":"2024-04-21T20:06:38.519290Z","shell.execute_reply.started":"2024-04-21T20:06:38.509958Z","shell.execute_reply":"2024-04-21T20:06:38.518424Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"epsilon = 0.5  # Exploration rate\nnum_rounds = 100  # Number of rounds to simulate\n\nselected_arms, total_reward = epsilon_greedy_matchmaking(user_id, user_data, num_arms, epsilon, num_rounds)\nprint(\"Selected Arms:\", selected_arms)\nprint(\"Total Reward:\", total_reward)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:38.520320Z","iopub.execute_input":"2024-04-21T20:06:38.521294Z","iopub.status.idle":"2024-04-21T20:06:38.655926Z","shell.execute_reply.started":"2024-04-21T20:06:38.521249Z","shell.execute_reply":"2024-04-21T20:06:38.654824Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Selected Arms: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 667, 0, 0, 0, 0, 0, 402, 717, 0, 0, 0, 0, 0, 404, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 721, 701, 825, 0, 0, 0, 312, 472, 0, 0, 740, 0, 0, 0, 815, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nTotal Reward: 70\n","output_type":"stream"}]},{"cell_type":"markdown","source":"simulation thompson sampling","metadata":{}},{"cell_type":"code","source":"def thompson_sampling_matchmaking(user_id, user_data, num_arms, num_rounds):\n    alpha = np.ones(num_arms)\n    beta = np.ones(num_arms)\n    total_reward = 0\n    selected_arms = []\n\n    for _ in range(num_rounds):\n        # Sample from the Beta distribution for each arm and choose the one with the highest sample\n        chosen_arm_index = np.argmax([np.random.beta(a + 1, b + 1) for a, b in zip(alpha, beta)])\n        chosen_arm = user_data['match_id'].unique()[chosen_arm_index]\n        \n        # Simulate getting a reward for the chosen arm from the user interactions\n        reward_row = user_data[(user_data['user_id'] == user_id) & (user_data['match_id'] == chosen_arm)].sample()\n        reward = reward_row['response'].values[0]\n        total_reward += reward\n\n        # If the reward is 1, add the arm to the list of selected arms\n        if reward == 1:\n            selected_arms.append(chosen_arm)\n        \n        # Update the alpha and beta values for the chosen arm\n        alpha[chosen_arm_index] += reward\n        beta[chosen_arm_index] += (1 - reward)\n\n    return selected_arms, total_reward\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:38.657146Z","iopub.execute_input":"2024-04-21T20:06:38.657449Z","iopub.status.idle":"2024-04-21T20:06:38.667341Z","shell.execute_reply.started":"2024-04-21T20:06:38.657423Z","shell.execute_reply":"2024-04-21T20:06:38.666105Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"selected_arms, total_reward = thompson_sampling_matchmaking(user_id, user_data, num_arms, num_rounds)\nprint(\"Selected Arms:\", selected_arms)\nprint(\"Total Reward:\", total_reward)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:38.668831Z","iopub.execute_input":"2024-04-21T20:06:38.669204Z","iopub.status.idle":"2024-04-21T20:06:39.042565Z","shell.execute_reply.started":"2024-04-21T20:06:38.669175Z","shell.execute_reply":"2024-04-21T20:06:39.041387Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Selected Arms: [203, 209, 816, 73, 739, 593, 218, 673, 738, 489, 752, 193, 258, 393, 390, 563, 254, 643, 493, 438, 673, 150, 844, 184, 863, 477, 740, 690, 221, 319, 433, 334, 570, 786, 345, 746, 166, 462, 602]\nTotal Reward: 39\n","output_type":"stream"}]},{"cell_type":"markdown","source":"simulation linear greedy","metadata":{}},{"cell_type":"code","source":"def linear_greedy_epsilon_matchmaking(user_id, user_data, num_arms, epsilon, num_rounds):\n    model = LinearRegression()\n    total_reward = 0\n    selected_arms = []\n    \n    # Initialize the dataset for training the model\n    training_data = pd.DataFrame()\n    for arm in range(num_arms):\n        arm_data = user_data[user_data['match_id'] == arm]\n        if not arm_data.empty:\n            training_data = pd.concat([training_data, arm_data.iloc[:1]], ignore_index=True)\n    \n    # Check if there are any entries in the training data before fitting\n    if not training_data.empty:\n        model.fit(training_data[['similarity_score']], training_data['response'])\n\n        for _ in range(num_rounds):\n            if random.random() < epsilon:\n                # Explore\n                chosen_arm = random.choice(user_data['match_id'].unique())\n            else:\n                # Exploit: Choose the arm with the highest predicted reward\n                predictions = model.predict(user_data[['similarity_score']])\n                user_data.loc[:, 'predicted_reward'] = predictions\n                chosen_arm = user_data.loc[user_data['predicted_reward'].idxmax(), 'match_id']\n            \n            # Observe the reward and update the model accordingly\n            reward_row = user_data[(user_data['user_id'] == user_id) & (user_data['match_id'] == chosen_arm)].sample()\n            reward = reward_row['response'].values[0]\n            total_reward += reward\n\n            # If the reward is 1, add the arm to the list of selected arms\n            if reward == 1:\n                selected_arms.append(chosen_arm)\n            \n            # Add this data point to the training dataset and retrain the model\n            if chosen_arm in training_data['match_id'].values:\n                # Update the existing data point\n                arm_index = training_data.index[training_data['match_id'] == chosen_arm].tolist()[0]\n                training_data.loc[arm_index, 'response'] = reward\n            else:\n                # Add new data point\n                training_data = pd.concat([training_data, reward_row], ignore_index=True)\n            model.fit(training_data[['similarity_score']], training_data['response'])\n\n    return selected_arms, total_reward\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:39.044166Z","iopub.execute_input":"2024-04-21T20:06:39.044620Z","iopub.status.idle":"2024-04-21T20:06:39.059433Z","shell.execute_reply.started":"2024-04-21T20:06:39.044590Z","shell.execute_reply":"2024-04-21T20:06:39.058118Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"selected_arms, total_reward = linear_greedy_epsilon_matchmaking(user_id, user_data, num_arms, epsilon, num_rounds)\nprint(\"Selected Arms:\", selected_arms)\nprint(\"Total Reward:\", total_reward)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:10:31.636351Z","iopub.execute_input":"2024-04-21T20:10:31.637137Z","iopub.status.idle":"2024-04-21T20:11:25.290498Z","shell.execute_reply.started":"2024-04-21T20:10:31.637073Z","shell.execute_reply":"2024-04-21T20:11:25.289429Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Selected Arms: [2, 2, 2, 2, 2, 187, 2, 2, 741, 2, 2, 2, 2, 426, 2, 2, 2, 372, 2, 475, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 675, 2, 2, 2, 30, 2, 2, 131, 2, 2, 2, 2, 2, 2, 2, 2, 2, 840, 2, 2, 2, 360, 2, 2, 643, 2, 2, 2, 2, 2, 2, 772, 30, 2, 57, 2, 824, 2, 2, 2, 2, 2, 2, 2, 347, 2, 2, 2, 2, 2, 2, 2, 2, 746, 2, 2, 2, 2, 2, 2, 354, 2, 2, 2, 2, 2, 2, 708, 314, 2, 2, 2, 418, 2, 2, 2, 2, 2, 400, 115, 2, 2, 2, 2, 2, 2, 498, 593, 322, 2, 2, 744, 2, 2, 2, 393, 364, 2, 2, 2, 2, 2, 2, 269, 145, 356, 2, 2, 701, 740, 776, 2, 2, 2, 2, 225, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 56, 2, 2, 265, 324, 2, 2, 214, 2, 783, 2, 2, 796, 2, 2, 19, 21, 2, 2, 2, 2, 2, 221, 727, 2, 2, 322, 2, 2, 314, 2, 2, 496, 690, 2, 2, 2, 357, 2, 735, 275, 2, 506, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 645, 2, 2, 761, 2, 2, 731, 855, 2, 2, 2, 539, 2, 2, 2, 2, 2, 2, 134, 69, 2, 2, 2, 2, 2, 2, 2, 2, 2, 73, 2, 2, 2, 2, 2, 193, 2, 2, 393, 621, 2, 2, 2, 435, 2, 875, 2, 115, 2, 2, 2, 845, 2, 2, 2, 2, 258, 2, 342, 2, 2, 2, 2, 2, 461, 2, 2, 662, 17, 2, 2, 2, 2, 2, 2, 629, 388, 2, 2, 2, 2, 2, 272, 2, 2, 2, 37, 2, 2, 2, 2, 172, 2, 2, 254, 2, 412, 9, 2, 2, 2, 2, 2, 2, 313, 2, 735, 2, 2, 2, 2, 2, 361, 673, 65, 2, 166, 764, 394, 2, 2, 788, 2, 2, 2, 2, 2, 776, 671, 2, 2, 2, 41, 693, 2, 2, 186, 2, 2, 2, 737, 203, 2, 780, 2, 333, 2, 2, 2, 382, 111, 2, 2, 2, 353, 2, 2, 2, 270, 60, 2, 449, 2, 724, 2, 2, 2, 2, 2, 2, 186, 2, 720, 2, 2, 2, 621, 2, 2, 2, 613, 2, 2, 2, 824, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 396, 626, 2, 2, 468, 2, 2, 2, 2, 2, 2, 2, 186, 19, 2, 2, 784, 163, 783, 191, 2, 2, 215, 2, 2, 2, 2, 788, 2, 732, 2, 2, 2, 489, 2, 2, 403, 643, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 509, 735, 125, 329, 881, 514, 263, 2, 2, 114, 2, 2, 2, 2, 2, 744, 319, 2, 73, 2, 2, 2, 2, 2, 2, 495, 2, 2, 2, 2, 193, 613, 2, 2, 2, 641, 2, 2, 2, 404, 477, 2, 2, 2, 2, 102, 2, 2, 57, 2, 69, 2, 3, 2, 170, 345, 2, 2, 324, 2, 2, 2, 225, 2, 2, 433, 2, 2, 145, 764, 2, 2, 875, 2, 2, 2, 2, 2, 2, 2, 520, 402, 187, 2, 2, 2, 2, 2, 302, 2, 875, 2, 2, 2, 2, 2, 2, 213, 2, 2, 2, 2, 2, 731, 184, 708, 2, 412, 2, 2, 2, 2, 34, 49, 2, 2, 2, 402, 347, 2, 272, 2, 2, 2, 213, 638, 2, 2, 2, 23, 2, 2, 2, 2, 2, 2, 2, 2, 850, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 102, 2, 613, 2, 2, 2, 2, 881, 2, 2, 338, 2, 2, 602, 450, 138, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 784, 2, 2, 2, 2, 2, 2, 2, 645, 2, 2, 2, 2, 144, 2, 626, 453, 2, 2, 2, 2, 2, 844, 39, 2, 299, 2, 752, 2, 2, 784, 2, 2, 314, 74, 2, 2, 372, 2, 2, 2, 2, 2, 2, 2, 2, 225, 178, 2, 2, 2, 2, 129, 636, 2, 412, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 337, 2, 421, 2, 2, 2, 2, 2, 2, 751, 2, 2, 213, 111, 622, 2, 2, 302, 537, 2, 439, 180, 786, 2, 336, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 334, 150, 319, 2, 587, 610, 413, 2, 2, 2, 2, 498, 626, 471, 2, 2, 2, 2, 2, 255, 2, 2, 2, 2, 2, 2, 2, 2, 255, 2, 2, 394, 449, 2, 2, 270, 316, 641, 2, 2, 2, 426, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 799, 2, 2, 17, 318, 2, 2, 2, 507, 2, 2, 221, 519, 2, 2, 788, 2, 2, 2, 2, 200, 2, 2, 2, 2, 2, 2, 2, 2, 361, 2, 74, 462, 2, 2, 659, 2, 2, 2, 2, 2, 2, 449, 2, 2, 2, 712, 2, 2, 2, 2, 2, 2, 2, 2, 2, 314, 2, 2, 2, 2, 2, 2, 2, 2, 62, 23, 2, 2, 2, 2, 258, 2, 2, 2, 626, 2, 477, 2, 145, 2, 2, 2, 2, 2, 2, 2, 698, 855, 2, 2, 268, 2, 286, 2, 2, 2, 2, 2, 2, 172, 2, 2, 2, 2, 2, 2, 2, 2, 2, 21, 2, 770, 2, 209, 2, 2, 2, 2, 426, 268, 2, 720, 2, 2, 2, 2, 537, 348, 2, 145, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 761, 2, 2, 2, 2, 2, 693, 2, 2, 2, 643, 2, 7, 2, 299, 844, 322, 2, 2, 2, 2, 2, 2, 2, 2, 7, 509, 2, 2, 2, 2, 2, 695, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 816, 286, 435, 39, 2, 2, 2, 2, 334, 2, 2, 788, 2, 2, 2, 449, 21, 209, 2, 2, 2, 720, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 570, 2, 432, 2, 2, 2, 2, 2, 822, 2, 2, 5, 361, 166, 2, 2, 138, 2, 2, 134, 2, 2, 2, 2, 2, 2, 2, 287, 682, 509, 2, 2, 2, 337, 2, 875, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 159, 2, 2, 2, 125, 2, 2, 165, 2, 2, 2, 2, 2, 2, 2, 2, 65, 2, 2, 2, 2, 2, 2, 2, 2, 761, 2, 2, 2, 2, 687, 138, 2, 2, 201, 2, 2, 2, 593, 2, 2, 850, 660, 2, 2, 2, 2, 2, 2, 2, 2, 872, 2, 2, 887, 2, 2, 2, 2, 2, 56, 662, 842, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 669, 2, 2, 761, 2, 334, 824, 2, 150, 418, 2, 2, 2, 180, 2, 2, 2, 2, 2, 449, 145, 498, 537, 2, 2, 2, 2, 2, 2, 2, 165, 2, 2, 2, 2, 394, 2, 439, 2, 2, 2, 2, 2, 2, 73, 2, 2, 2, 2, 347, 2, 558, 2, 2, 2, 30, 2, 2, 2, 2, 672, 2, 2, 2, 439, 5, 2, 2, 2, 2, 326, 2, 701, 2, 2, 2, 695, 2, 2, 390, 2, 74, 2, 2, 2, 2, 395, 49, 2, 2, 213, 2, 2, 2, 2, 563, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 542, 2, 362, 2, 296, 180, 2, 2, 98, 2, 640, 2, 124, 2, 2, 2, 2, 2, 203, 2, 2, 2, 2, 2, 400, 2, 2, 2, 2, 2, 131, 2, 2, 879, 643, 324, 2, 2, 2, 507, 2, 2, 2, 721, 2, 254, 2, 37, 606, 2, 570, 108, 2, 2, 2, 319, 2, 2, 2, 744, 2, 2, 2, 2, 2, 326, 2, 2, 313, 2, 2, 825, 2, 243, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 218, 2, 2, 2, 215, 2, 2, 2, 2, 2, 454, 799, 850, 2, 2, 413, 418, 2, 2, 2, 159, 539, 337, 2, 2, 780, 715, 502, 2, 2, 816, 2, 2, 2, 2, 2, 2, 2, 159, 2, 721, 2, 842, 2, 2, 581, 471, 2, 2, 2, 2, 2, 840, 669, 2, 2, 2, 2, 663, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 319, 2, 2, 2, 427, 2, 2, 502, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 587, 2, 2, 393, 2, 342, 682, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 643, 2, 67, 764, 337, 2, 2, 2, 2, 453, 2, 2, 468, 2, 2, 2, 2, 2, 2, 200, 2, 2, 2, 2, 509, 2, 2, 60, 159, 2, 2, 2, 427, 253, 142, 2, 2, 2, 2, 2, 2, 2, 505, 2, 2, 134, 2, 2, 2, 2, 2, 2, 2, 2, 2, 507, 537, 2, 344, 2, 2, 2, 2, 2, 2, 2, 2, 2, 786, 2, 2, 471, 2, 2, 2, 2, 319, 618, 2, 2, 2, 560, 2, 348, 2, 142, 2, 2, 2, 2, 2, 2, 3, 215, 2, 2, 2, 2, 738, 2, 2, 402, 2, 2, 2, 2, 477, 433, 2, 626, 2, 2, 2, 144, 2, 2, 2, 2, 2, 2, 2, 2, 746, 2, 471, 2, 21, 72, 2, 2, 2, 2, 2, 2, 2, 2, 59, 602, 454, 2, 575, 2, 2, 2, 2, 337, 2, 641, 2, 570, 2, 67, 2, 835, 2, 2, 2, 2, 2, 2, 2, 2, 739, 2, 2, 2, 2, 2, 2, 732, 739, 493, 191, 2, 2, 299, 5, 821, 2, 2, 2, 2, 299, 2, 243, 698, 519, 299, 65, 2, 2, 519, 780, 2, 2, 2, 2, 125, 2, 2, 2, 119, 2, 718, 316, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 764, 2, 2, 2, 2, 460, 2, 432, 2, 570, 2, 2, 2, 165, 388, 2, 2, 438, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 498, 2, 324, 783, 641, 2, 2, 761, 2, 2, 2, 2, 2, 2, 2, 2, 329, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 329, 2, 2, 2, 2, 746, 313, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 454, 2, 732, 2, 2, 2, 2, 2, 2, 2, 2, 746, 2, 2, 602, 2, 2, 2, 2, 618, 2, 2, 2, 115, 537, 263, 41, 2, 2, 2, 2, 138, 294, 2, 2, 507, 2, 2, 2, 2, 2, 2, 506, 823, 2, 163, 2, 2, 150, 2, 2, 606, 2, 2, 3, 124, 2, 507, 2, 2, 2, 2, 2, 178, 2, 344, 2, 2, 2, 509, 184, 2, 2, 2, 2, 2, 345, 2, 2, 2, 2, 717, 2, 2, 361, 2, 2, 2, 2, 2, 2, 2, 154, 2, 2, 41, 56, 2, 2, 388, 2, 2, 2, 404, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 599, 2, 2, 2, 2, 2, 2, 226, 872, 2, 2, 2, 2, 144, 2, 2, 2, 2, 2, 574, 2, 2, 441, 2, 748, 2, 2, 2, 2, 345, 396, 2, 2, 2, 2, 2, 593, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 574, 7, 2, 731, 2, 2, 79, 2, 2, 2, 2, 2, 2, 2, 2, 98, 2, 2, 22, 2, 2, 2, 2, 2, 2, 629, 2, 2, 2, 2, 507, 2, 893, 2, 2, 2, 2, 776, 2, 2, 2, 2, 2, 2, 548, 530, 2, 2, 102, 2, 2, 2, 2, 2, 2, 2, 2, 2, 893, 2, 2, 312, 2, 2, 2, 2, 2, 2, 2, 296, 2, 2, 393, 2, 478, 2, 2, 2, 2, 2, 2, 2, 560, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 788, 2, 226, 2, 2, 2, 2, 2, 2, 509, 2, 2, 542, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 629, 2, 2, 2, 23, 2, 2, 2, 2, 225, 2, 2, 200, 2, 2, 2, 2, 184, 2, 770, 2, 727, 2, 2, 2, 744, 2, 2, 2, 2, 2, 2, 299, 2, 2, 2, 2, 2, 433, 2, 525, 2, 2, 449, 2, 2, 2, 2, 74, 609, 460, 2, 2, 2, 2, 2, 23, 2, 2, 2, 2, 215, 2, 2, 2, 421, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 752, 449, 2, 2, 450, 2, 2, 2, 2, 2, 2, 620, 2, 129, 626, 2, 850, 2, 2, 433, 2, 2, 2, 751, 2, 180, 319, 2, 268, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 67, 2, 226, 2, 659, 2, 2, 2, 2, 823, 2, 599, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 390, 2, 2, 475, 2, 114, 2, 525, 468, 287, 2, 786, 2, 2, 2, 2, 2, 2, 2, 2, 2, 69, 2, 2, 403, 2, 2, 2, 2, 2, 663, 402, 2, 2, 2, 2, 354, 61, 361, 2, 2, 2, 574, 2, 5, 2, 788, 2, 299, 476, 2, 184, 2, 353, 2, 2, 2, 2, 2, 2, 2, 296, 2, 2, 2, 2, 2, 286, 2, 587, 879, 2, 98, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 2, 621, 2, 2, 2, 2, 502, 2, 39, 364, 787, 2, 720, 2, 2, 2, 2, 608, 2, 2, 72, 2, 218, 2, 2, 2, 2, 2, 394, 2, 394, 2, 687, 2, 2, 2, 2, 2, 2, 610, 2, 2, 574, 2, 2, 2, 2, 2, 2, 243, 2, 2, 2, 477, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 502, 2, 2, 2, 2, 715, 2, 2, 364, 2, 2, 772, 2, 2, 2, 2, 2, 2, 2, 2, 687, 2, 2, 2, 2, 2, 2, 2, 511, 2, 2, 715, 2, 2, 2, 2, 748, 2, 454, 2, 2, 2, 2, 2, 2, 2, 636, 2, 2, 2, 2, 151, 2, 675, 824, 2, 0, 2, 119, 2, 2, 2, 2, 461, 2, 2, 2, 2, 221, 2, 2, 2, 822, 432, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 267, 2, 2, 2, 2, 2, 2, 182, 2, 2, 2, 2, 2, 454, 2, 2, 2, 221, 115, 2, 326, 2, 2, 2, 2, 186, 2, 213, 735, 2, 2, 2, 2, 21, 2, 775, 2, 887, 2, 268, 200, 2, 2, 69, 2, 672, 2, 877, 748, 304, 824, 2, 2, 780, 435, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 660, 2, 2, 2, 581, 2, 2, 2, 2, 334, 2, 404, 319, 2, 114, 667, 746, 2, 2, 2, 251, 2, 732, 2, 2, 643, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 870, 2, 863, 2, 2, 125, 773, 2, 403, 2, 2, 2, 2, 2, 2, 2, 2, 698, 2, 2, 2, 502, 523, 2, 720, 2, 2, 2, 2, 2, 2, 2, 2, 2, 693, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 629, 2, 2, 2, 338, 2, 7, 2, 2, 2, 2, 2, 2, 6, 2, 324, 2, 2, 269, 2, 213, 2, 2, 2, 2, 2, 2, 2, 159, 2, 505, 2, 2, 2, 2, 2, 630, 2, 2, 2, 2, 2, 2, 2, 2, 2, 354, 2, 213, 145, 780, 2, 840, 2, 2, 5, 2, 426, 2, 2, 2, 690, 671, 394, 735, 2, 2, 37, 478, 2, 2, 2, 2, 2, 318, 2, 2, 2, 815, 2, 2, 2, 2, 392, 2, 2, 2, 2, 2, 2, 643, 2, 2, 415, 203, 2, 2, 2, 2, 2, 324, 2, 2, 2, 662, 314, 2, 2, 2, 2, 2, 796, 2, 2, 2, 2, 2, 221, 2, 2, 2, 2, 2, 2, 687, 2, 2, 662, 870, 2, 2, 2, 15, 2, 2, 2, 2, 498, 2, 23, 214, 2, 2, 2, 2, 102, 395, 2, 2, 2, 799, 2, 2, 2, 2, 225, 2, 2, 2, 2, 712, 2, 2, 2, 2, 2, 2, 2, 835, 396, 6, 2, 593, 2, 291, 209, 2, 355, 2, 2, 621, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 124, 2, 2, 2, 2, 115, 57, 2, 776, 558, 2, 2, 138, 2, 2, 2, 2, 2, 59, 881, 2, 498, 2, 2, 134, 454, 2, 2, 151, 2, 2, 2, 2, 2, 885, 2, 2, 2, 514, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 525, 2, 2, 2, 2, 6, 413, 2, 454, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 404, 2, 2, 2, 2, 2, 815, 2, 67, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 539, 2, 79, 2, 30, 2, 309, 2, 2, 2, 61, 2, 2, 2, 2, 2, 2, 2, 432, 2, 2, 2, 2, 2, 502, 2, 2, 2, 2, 2, 712, 2, 2, 2, 744, 134, 2, 587, 489, 826, 2, 2, 2, 2, 2, 2, 662, 2, 2, 542, 2, 2, 441, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 845, 2, 191, 2, 2, 69, 2, 2, 2, 2, 382, 251, 2, 2, 2, 2, 2, 877, 825, 226, 2, 570, 2, 138, 821, 2, 2, 2, 2, 2, 2, 2, 720, 2, 2, 2, 558, 2, 2, 2, 2, 2, 2, 39, 2, 2, 2, 2, 23, 2, 712, 243, 2, 2, 2, 2, 2, 2, 667, 2, 2, 2, 608, 2, 2, 2, 270, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 815, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 402, 2, 2, 690, 2, 670, 2, 2, 2, 764, 2, 827, 2, 23, 178, 2, 2, 2, 825, 887, 2, 560, 2, 150, 2, 446, 2, 629, 354, 2, 364, 2, 450, 2, 267, 2, 2, 2, 2, 69, 2, 2, 461, 2, 254, 2, 2, 2, 613, 2, 2, 2, 875, 2, 2, 435, 2, 2, 345, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 348, 2, 2, 2, 2, 2, 2, 2, 426, 2, 2, 2, 2, 2, 2, 621, 2, 2, 2, 388, 2, 746, 827, 2, 2, 2, 714, 2, 2, 2, 2, 314, 2, 2, 796, 2, 2, 885, 2, 2, 2, 2, 2, 2, 764, 22, 2, 2, 2, 2, 2, 2, 2, 453, 142, 673, 312, 879, 2, 62, 2, 780, 2, 2, 450, 2, 2, 79, 2, 2, 2, 2, 2, 2, 344, 2, 2, 2, 2, 2, 2, 2, 701, 2, 2, 2, 542, 2, 887, 2, 2, 2, 2, 2, 2, 2, 2, 727, 2, 2, 2, 2, 539, 2, 2, 2, 2, 2, 2, 741, 433, 2, 148, 855, 432, 2, 663, 502, 2, 780, 2, 2, 2, 2, 2, 357, 2, 115, 748, 17, 65, 2, 2, 439, 34, 2, 2, 764, 2, 746, 875, 2, 23, 2, 263, 2, 254, 2, 2, 2, 2, 636, 2, 2, 309, 548, 124, 2, 2, 2, 731, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 446, 2, 2, 608, 2, 2, 2, 2, 2, 184, 330, 2, 2, 2, 2, 438, 2, 2, 2, 2, 2, 2, 203, 2, 690, 2, 537, 2, 2, 2, 2, 2, 37, 2, 2, 821, 309, 2, 2, 255, 2, 2, 537, 2, 2, 2, 2, 2, 2, 2, 2, 272, 393, 2, 272, 2, 523, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 131, 2, 2, 178, 2, 2, 2, 2, 2, 215, 2, 131, 2, 2, 2, 114, 2, 220, 180, 2, 2, 2, 2, 2, 2, 186, 260, 2, 2, 184, 2, 2, 2, 209, 2, 2, 2, 505, 2, 2, 2, 2, 2, 2, 2, 2, 2, 253, 2, 2, 2, 2, 221, 2, 2, 2, 441, 302, 2, 2, 2, 159, 2, 2, 2, 2, 2, 2, 2, 2, 2, 135, 2, 421, 489, 2, 2, 2, 2, 2, 2, 2, 2, 2, 489, 453, 2, 2, 203, 2, 558, 2, 2, 893, 2, 2, 2, 740, 721, 2, 2, 2, 2, 2, 2, 2, 348, 2, 2, 2, 2, 39, 2, 2, 671, 2, 663, 2, 638, 2, 30, 2, 2, 265, 214, 2, 475, 748, 2, 712, 342, 752, 2, 2, 2, 2, 2, 2, 799, 2, 216, 840, 2, 2, 2, 2, 2, 2, 2, 2, 626, 2, 662, 2, 2, 432, 2, 2, 2, 2, 2, 2, 2, 144, 2, 2, 2, 2, 2, 523, 2, 2, 2, 126, 324, 2, 2, 2, 2, 2, 2, 2, 822, 2, 253, 746, 2, 618, 2, 265, 2, 2, 263, 2, 262, 2, 187, 2, 2, 2, 2, 2, 599, 333, 2, 2, 502, 2, 2, 2, 2, 842, 2, 2, 2, 221, 454, 2, 2, 326, 2, 19, 2, 461, 662, 220, 2, 2, 2, 2, 816, 361, 2, 2, 135, 2, 672, 2, 2, 2, 2, 701, 2, 2, 2, 2, 2, 659, 2, 775, 2, 2, 2, 2, 2, 893, 2, 2, 2, 2, 2, 2, 714, 2, 636, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 842, 2, 2, 2, 2, 2, 2, 840, 2, 2, 621, 2, 2, 2, 2, 2, 2, 630, 2, 2, 827, 2, 2, 2, 2, 2, 2, 184, 382, 2, 388, 2, 291, 2, 672, 638, 2, 2, 2, 2, 2, 98, 2, 17, 2, 2, 2, 2, 796, 2, 2, 2, 468, 2, 2, 2, 39, 2, 2, 395, 714, 2, 2, 2, 2, 2, 2, 2, 2, 361, 2, 2, 2, 618, 2, 2, 2, 74, 260, 2, 523, 2, 2, 2, 2, 640, 126, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 738, 2, 404, 2, 2, 2, 243, 2, 2, 2, 2, 2, 2, 877, 67, 151, 2, 2, 2, 2, 2, 2, 2, 2, 214, 2, 342, 326, 2, 2, 708, 2, 866, 7, 2, 2, 2, 738, 2, 2, 2, 2, 61, 2, 783, 2, 2, 2, 2, 111, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 784, 2, 468, 2, 2, 2, 2, 2, 163, 2, 2, 2, 2, 2, 2, 2, 2, 2, 337, 2, 2, 2, 2, 2, 2, 2, 293, 582, 864, 314, 2, 2, 2, 776, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 808, 2, 2, 2, 361, 2, 2, 2, 2, 2, 689, 2, 2, 2, 2, 2, 2, 2, 2, 2, 347, 2, 2, 2, 2, 2, 2, 751, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 872, 2, 626, 2, 2, 2, 2, 2, 2, 330, 587, 863, 2, 2, 2, 718, 718, 2, 2, 267, 670, 2, 2, 2, 2, 2, 2, 511, 2, 2, 2, 2, 2, 2, 2, 2, 721, 2, 2, 2, 337, 739, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 506, 2, 2, 220, 2, 2, 2, 126, 2, 2, 2, 453, 2, 770, 2, 2, 845, 2, 2, 2, 2, 2, 2, 509, 2, 6, 338, 2, 2, 835, 502, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 144, 2, 2, 270, 2, 2, 2, 2, 2, 2, 263, 472, 2, 395, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 294, 2, 2, 182, 2, 2, 2, 2, 2, 67, 2, 2, 2, 2, 2, 2, 2, 2, 2, 881, 2, 2, 2, 2, 2, 112, 2, 2, 2, 2, 638, 2, 2, 180, 344, 2, 73, 2, 296, 2, 2, 2, 739, 2, 2, 2, 2, 2, 2, 2, 79, 2, 2, 114, 220, 2, 2, 2, 2, 2, 2, 296, 2, 2, 30, 2, 2, 2, 2, 2, 34, 2, 2, 698, 2, 718, 2, 2, 2, 2, 2, 662, 2, 776, 57, 2, 59, 2, 2, 2, 2, 2, 815, 2, 2, 2, 2, 2, 67, 2, 2, 2, 2, 2, 2, 2, 509, 404, 2, 2, 2, 875, 2, 2, 2, 460, 2, 2, 3, 111, 724, 138, 2, 2, 2, 2, 345, 2, 2, 2, 2, 2, 2, 342, 2, 2, 570, 2, 2, 412, 2, 2, 108, 394, 641, 49, 2, 2, 2, 114, 2, 2, 2, 2, 2, 2, 2, 2, 2, 415, 151, 260, 587, 2, 2, 2, 254, 2, 2, 187, 2, 2, 2, 427, 62, 698, 885, 2, 215, 216, 2, 2, 2, 2, 2, 98, 2, 2, 2, 2, 2, 299, 2, 2, 476, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 225, 2, 2, 2, 682, 2, 2, 496, 2, 2, 2, 2, 2, 2, 477, 2, 357, 345, 2, 735, 2, 2, 2, 2, 2, 2, 62, 2, 2, 2, 739, 2, 489, 2, 2, 2, 2, 2, 2, 2, 2, 2, 673, 2, 2, 2, 599, 2, 748, 2, 2, 2, 512, 2, 2, 2, 2, 201, 476, 2, 2, 560, 2, 2, 2, 357, 2, 111, 2, 2, 330, 2, 334, 2, 823, 2, 2, 2, 2, 2, 393, 2, 2, 2, 291, 468, 712, 620, 2, 751, 2, 2, 2, 2, 2, 2, 166, 2, 180, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 879, 2, 2, 2, 2, 2, 2, 184, 2, 2, 2, 695, 2, 260, 214, 2, 2, 2, 2, 836, 842, 2, 2, 2, 2, 324, 2, 2, 450, 2, 302, 65, 2, 2, 2, 690, 2, 2, 2, 2, 2, 2, 2, 815, 318, 2, 2, 60, 2, 2, 2, 209, 2, 2, 454, 2, 672, 2, 2, 2, 2, 314, 2, 786, 2, 2, 2, 2, 2, 2, 270, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 326, 2, 2, 2, 2, 2, 511, 2, 2, 2, 2, 2, 2, 2, 263, 2, 2, 2, 2, 2, 2, 2, 454, 2, 353, 257, 435, 2, 2, 2, 2, 2, 2, 2, 318, 2, 2, 824, 2, 2, 2, 2, 203, 433, 2, 2, 2, 124, 574, 2, 2, 2, 418, 693, 2, 2, 2, 2, 2, 2, 2, 2, 433, 2, 2, 575, 2, 643, 182, 2, 2, 2, 2, 2, 2, 2, 2, 502, 2, 2, 2, 142, 2, 698, 2, 731, 2, 602, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 741, 2, 2, 2, 2, 433, 2, 2, 2, 2, 200, 395, 787, 2, 312, 2, 2, 2, 2, 2, 2, 2, 270, 3, 15, 2, 2, 2, 2, 662, 2, 2, 2, 2, 2, 2, 186, 821, 2, 2, 714, 2, 2, 2, 2, 641, 2, 2, 2, 2, 2, 2, 2, 388, 2, 689, 472, 2, 2, 2, 2, 2, 2, 2, 2, 2, 172, 2, 2, 2, 2, 2, 2, 870, 2, 2, 2, 2, 2, 6, 2, 2, 2, 2, 2, 675, 220, 2, 2, 2, 735, 2, 2, 2, 2, 126, 2, 507, 2, 294, 2, 2, 2, 2, 2, 2, 2, 2, 2, 39, 2, 2, 2, 2, 2, 2, 640, 415, 2, 2, 2, 2, 2, 2, 2, 65, 2, 2, 253, 2, 2, 2, 5, 2, 721, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 372, 2, 2, 2, 2, 2, 2, 2, 2, 2, 626, 2, 2, 2, 2, 6, 2, 2, 2, 2, 2, 548, 2, 881, 2, 2, 2, 2, 221, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 441, 2, 2, 2, 822, 2, 2, 2, 299, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 65, 2, 2, 2, 2, 2, 606, 2, 2, 2, 2, 200, 2, 2, 2, 2, 2, 142, 2, 718, 2, 2, 2, 2, 864, 2, 581, 67, 2, 2, 2, 2, 2, 2, 472, 2, 60, 2, 787, 372, 2, 2, 2, 2, 2, 2, 887, 203, 720, 2, 2, 2, 2, 342, 2, 2, 23, 98, 2, 2, 2, 2, 2, 2, 220, 2, 2, 2, 438, 2, 2, 254, 2, 2, 2, 863, 2, 2, 835, 2, 2, 2, 2, 2, 2, 2, 119, 2, 2, 2, 788, 2, 382, 2, 191, 2, 2, 329, 2, 2, 2, 2, 319, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 844, 2, 2, 2, 2, 2, 2, 2, 2, 512, 2, 2, 2, 2, 2, 2, 821, 2, 2, 2, 2, 2, 2, 2, 690, 2, 454, 2, 2, 2, 2, 2, 2, 468, 213, 2, 2, 2, 2, 67, 2, 2, 2, 2, 2, 433, 2, 2, 2, 687, 2, 2, 2, 2, 2, 2, 746, 216, 2, 2, 2, 2, 2, 636, 514, 2, 258, 2, 885, 808, 2, 2, 2, 2, 2, 2, 119, 2, 2, 2, 826, 775, 2, 748, 2, 2, 2, 2, 2, 180, 2, 2, 2, 2, 2, 2, 112, 2, 2, 2, 489, 783, 2, 621, 2, 669, 2, 439, 98, 495, 2, 2, 2, 2, 2, 382, 2, 2, 2, 2, 2, 2, 15, 2, 2, 2, 0, 329, 2, 2, 2, 2, 60, 2, 2, 2, 2, 715, 2, 275, 2, 2, 2, 840, 2, 2, 2, 2, 836, 2, 2, 2, 2, 225, 2, 863, 2, 2, 2, 836, 400, 2, 2, 2, 275, 786, 267, 2, 2, 2, 2, 2, 2, 345, 2, 337, 2, 2, 142, 2, 0, 294, 2, 2, 2, 2, 2, 825, 2, 2, 2, 2, 2, 2, 2, 2, 2, 382, 609, 893, 316, 287, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 460, 687, 2, 353, 5, 2, 2, 2, 337, 187, 875, 2, 2, 299, 507, 2, 2, 528, 2, 2, 2, 2, 2, 593, 2, 2, 2, 2, 2, 602, 2, 2, 841, 2, 2, 2, 2, 2, 2, 2, 2, 468, 2, 2, 2, 2, 2, 2, 821, 2, 2, 2, 56, 319, 2, 2, 2, 638, 418, 2, 182, 2, 2, 2, 2, 314, 39, 2, 2, 2, 2, 2, 2, 2, 2, 520, 2, 2, 893, 2, 2, 826, 2, 2, 2, 823, 2, 2, 2, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 2, 2, 875, 2, 2, 2, 519, 2, 5, 626, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 761, 675, 2, 184, 2, 2, 2, 2, 2, 845, 2, 2, 2, 126, 2, 2, 477, 735, 2, 2, 2, 2, 2, 2, 2, 2, 134, 2, 741, 2, 2, 2, 2, 687, 2, 2, 2, 2, 2, 2, 2, 2, 2, 773, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 302, 2, 215, 2, 2, 2, 2, 2, 864, 135, 836, 2, 682, 184, 2, 2, 2, 2, 2, 138, 582, 2, 73, 2, 2, 2, 826, 2, 872, 2, 2, 2, 693, 770, 2, 17, 2, 2, 2, 2, 2, 2, 2, 2, 432, 2, 840, 2, 135, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 372, 2, 2, 505, 2, 2, 2, 2, 2, 2, 558, 2, 506, 2, 671, 2, 636, 2, 2, 2, 364, 2, 2, 251, 2, 2, 560, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 475, 2, 2, 2, 2, 682, 2, 841, 821, 2, 2, 2, 2, 2, 560, 471, 2, 2, 2, 855, 2, 824, 2, 2, 2, 2, 2, 2, 67, 2, 2, 112, 2, 2, 2, 2, 748, 2, 22, 258, 2, 2, 850, 319, 2, 735, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 191, 2, 2, 2, 2, 2, 2, 475, 2, 7, 2, 255, 2, 2, 2, 268, 2, 2, 2, 2, 257, 2, 214, 19, 2, 19, 2, 333, 2, 2, 2, 2, 2, 2, 2, 2, 2, 302, 2, 2, 2, 682, 2, 2, 2, 69, 2, 489, 2, 2, 131, 2, 2, 574, 530, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 388, 739, 309, 2, 2, 2, 2, 2, 19, 2, 2, 799, 751, 145, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 454, 2, 712, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 326, 2, 2, 2, 2, 2, 2, 2, 621, 2, 542, 2, 673, 2, 2, 2, 2, 393, 2, 413, 293, 2, 2, 119, 166, 360, 2, 2, 2, 364, 2, 2, 2, 2, 2, 2, 2, 2, 493, 2, 2, 618, 344, 2, 718, 2, 2, 2, 877, 2, 610, 2, 2, 460, 2, 2, 394, 2, 836, 6, 2, 2, 2, 2, 314, 2, 751, 2, 2, 2, 2, 2, 2, 2, 142, 2, 2, 2, 124, 2, 2, 112, 2, 2, 2, 2, 2, 34, 2, 2, 2, 606, 2, 2, 333, 2, 514, 2, 203, 2, 2, 39, 2, 221, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 450, 2, 2, 872, 435, 2, 689, 2, 2, 2, 114, 2, 2, 2, 2, 193, 2, 2, 2, 2, 2, 191, 2, 313, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 542, 2, 2, 659, 2, 402, 2, 2, 519, 825, 2, 2, 2, 2, 764, 2, 2, 65, 2, 73, 2, 2, 2, 2, 2, 2, 2, 2, 2, 609, 2, 2, 2, 2, 2, 2, 2, 2, 626, 2, 2, 2, 2, 3, 114, 2, 519, 2, 2, 2, 226, 2, 2, 2, 2, 712, 2, 260, 2, 2, 2, 629, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 392, 2, 2, 2, 2, 74, 2, 314, 2, 2, 2, 2, 2, 2, 2, 708, 2, 471, 2, 2, 2, 2, 2, 2, 2, 251, 2, 2, 382, 2, 2, 2, 478, 2, 2, 2, 2, 404, 2, 2, 262, 124, 2, 2, 2, 2, 877, 2, 2, 2, 438, 333, 2, 2, 796, 166, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 850, 2, 318, 2, 2, 316, 2, 2, 2, 2, 2, 879, 2, 2, 2, 2, 2, 724, 2, 2, 539, 672, 2, 2, 2, 2, 2, 2, 2, 695, 413, 721, 2, 2, 2, 2, 2, 2, 2, 2, 360, 2, 2, 2, 293, 2, 2, 2, 741, 2, 2, 2, 17, 845, 2, 2, 2, 659, 2, 2, 2, 2, 2, 2, 2, 9, 2, 2, 866, 2, 2, 2, 2, 2, 2, 2, 319, 2, 2, 2, 727, 2, 396, 2, 2, 2, 413, 291, 2, 2, 824, 2, 2, 2, 2, 864, 2, 872, 2, 253, 2, 2, 2, 2, 823, 2, 172, 2, 2, 98, 2, 142, 344, 2, 2, 2, 2, 2, 2, 879, 2, 2, 257, 2, 2, 2, 0, 2, 186, 2, 2, 2, 593, 2, 2, 872, 2, 302, 2, 221, 864, 2, 2, 2, 2, 2, 836, 690, 319, 2, 2, 2, 2, 744, 796, 2, 348, 2, 203, 2, 2, 772, 875, 2, 2, 2, 610, 2, 2, 841, 2, 2, 2, 403, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 881, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 740, 2, 2, 2, 775, 2, 2, 2, 2, 752, 2, 2, 2, 2, 630, 2, 2, 2, 2, 2, 182, 629, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 17, 243, 2, 2, 2, 2, 2, 693, 2, 2, 2, 2, 2, 836, 2, 2, 2, 2, 2, 751, 786, 2, 182, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 111, 784, 2, 2, 178, 2, 415, 2, 2, 2, 2, 2, 2, 618, 621, 135, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 275, 2, 2, 2, 2, 630, 496, 669, 2, 2, 575, 2, 2, 2, 2, 2, 2, 372, 119, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 701, 364, 2, 2, 2, 2, 2, 606, 2, 2, 2, 108, 2, 2, 2, 824, 2, 2, 2, 2, 2, 39, 2, 881, 2, 257, 2, 799, 314, 708, 539, 841, 125, 630, 2, 2, 2, 2, 2, 2, 570, 2, 752, 493, 2, 2, 2, 2, 2, 2, 2, 732, 2, 2, 2, 2, 2, 372, 154, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 356, 309, 2, 2, 2, 855, 73, 2, 2, 291, 659, 433, 732, 2, 57, 2, 2, 2, 393, 2, 2, 840, 2, 2, 426, 879, 2, 2, 2, 253, 2, 643, 2, 2, 2, 2, 2, 2, 126, 2, 2, 477, 2, 2, 2, 2, 2, 620, 593, 2, 2, 2, 2, 2, 528, 786, 2, 2, 2, 37, 2, 2, 154, 2, 2, 505, 2, 2, 270, 2, 2, 2, 472, 2, 2, 2, 150, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 166, 2, 2, 2, 2, 2, 151, 2, 2, 2, 2, 2, 2, 2, 2, 505, 2, 2, 2, 2, 2, 2, 326, 6, 201, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 502, 471, 324, 2, 2, 2, 294, 2, 2, 2, 2, 2, 2, 355, 2, 866, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 842, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 400, 2, 2, 333, 2, 630, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 881, 275, 2, 2, 2, 2, 670, 201, 2, 2, 496, 2, 221, 226, 2, 732, 2, 275, 775, 863, 2, 2, 215, 2, 509, 2, 2, 2, 2, 2, 412, 808, 2, 2, 2, 2, 718, 2, 2, 184, 2, 2, 787, 2, 2, 2, 2, 2, 2, 735, 2, 2, 587, 73, 2, 2, 2, 821, 2, 2, 433, 638, 537, 825, 823, 2, 2, 2, 2, 2, 2, 2, 262, 2, 2, 2, 201, 2, 2, 645, 2, 2, 213, 2, 2, 2, 269, 2, 2, 2, 2, 2, 2, 669, 2, 761, 2, 2, 720, 2, 2, 2, 2, 2, 2, 2, 2, 2, 270, 299, 2, 2, 2, 2, 2, 2, 2, 2, 2, 362, 2, 885, 2, 695, 835, 2, 454, 2, 2, 2, 2, 2, 2, 2, 2, 660, 2, 2, 489, 2, 2, 2, 2, 2, 744, 2, 2, 2, 2, 270, 2, 693, 2, 2, 2, 2, 2, 2, 2, 220, 7, 468, 2, 2, 2, 112, 2, 737, 2, 855, 2, 2, 313, 2, 2, 660, 2, 2, 2, 2, 2, 2, 2, 2, 498, 2, 2, 708, 69, 178, 353, 2, 2, 126, 2, 2, 2, 776, 752, 2, 336, 60, 2, 2, 2, 260, 2, 2, 2, 2, 0, 2, 2, 2, 724, 2, 2, 2, 2, 2, 450, 2, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 355, 866, 2, 2, 2, 783, 2, 2, 2, 30, 475, 148, 39, 2, 2, 2, 2, 2, 472, 2, 2, 2, 2, 477, 2, 2, 2, 721, 2, 461, 2, 2, 2, 2, 2, 2, 446, 2, 2, 2, 3, 2, 186, 2, 2, 267, 2, 2, 2, 2, 2, 772, 2, 2, 2, 142, 2, 2, 582, 2, 2, 2, 172, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 357, 2, 530, 2, 2, 2, 2, 148, 2, 225, 150, 2, 2, 15, 2, 2, 2, 525, 2, 2, 2, 826, 260, 73, 2, 2, 2, 2, 511, 178, 689, 2, 823, 2, 864, 2, 2, 34, 253, 2, 2, 2, 2, 2, 2, 2, 2, 720, 2, 2, 2, 2, 2, 842, 669, 2, 2, 2, 621, 2, 2, 2, 2, 2, 2, 845, 2, 2, 478, 2, 2, 427, 357, 2, 2, 2, 9, 2, 2, 2, 2, 2, 2, 2, 2, 225, 34, 2, 220, 2, 2, 2, 2, 2, 2, 2, 426, 735, 2, 885, 2, 2, 2, 2, 2, 2, 2, 2, 220, 2, 2, 2, 2, 673, 2, 2, 2, 2, 2, 877, 267, 2, 737, 2, 2, 2, 2, 2, 2]\nTotal Reward: 6847\n","output_type":"stream"}]},{"cell_type":"code","source":"def linear_greedy_matchmaking(user_id, user_data, num_arms, num_rounds):\n    model = LinearRegression()\n    total_reward = 0\n    selected_arms = []\n    \n    # Initialize the dataset for training the model\n    training_data = pd.DataFrame()\n    for arm in range(num_arms):\n        arm_data = user_data[user_data['match_id'] == arm]\n        if not arm_data.empty:\n            # Start with one example for each arm if possible\n            training_data = pd.concat([training_data, arm_data.iloc[:1]], ignore_index=True)\n    \n    # Training the model on initial data if available\n    if not training_data.empty:\n        model.fit(training_data[['similarity_score']], training_data['response'])\n\n        for _ in range(num_rounds):\n            # Exploit: Choose the arm with the highest predicted reward\n            predictions = model.predict(user_data[['similarity_score']])\n            user_data.loc[:, 'predicted_reward'] = predictions\n            chosen_arm = user_data.loc[user_data['predicted_reward'].idxmax(), 'match_id']\n            \n            # Simulate getting a reward for the chosen arm from the user interactions\n            reward_row = user_data[(user_data['user_id'] == user_id) & (user_data['match_id'] == chosen_arm)].sample()\n            reward = reward_row['response'].values[0]\n            total_reward += reward\n\n            # If the reward is 1, add the arm to the list of selected arms\n            if reward == 1:\n                selected_arms.append(chosen_arm)\n            \n            # Update the training data and retrain the model\n            training_data = pd.concat([training_data, reward_row], ignore_index=True)\n            model.fit(training_data[['similarity_score']], training_data['response'])\n\n    return selected_arms, total_reward","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:40.305463Z","iopub.execute_input":"2024-04-21T20:06:40.305846Z","iopub.status.idle":"2024-04-21T20:06:40.319940Z","shell.execute_reply.started":"2024-04-21T20:06:40.305816Z","shell.execute_reply":"2024-04-21T20:06:40.318629Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"selected_arms, total_reward = linear_greedy_matchmaking(user_id, user_data, num_arms, num_rounds)\nprint(\"Selected Arms:\", selected_arms)\nprint(\"Total Reward:\", total_reward)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:40.322025Z","iopub.execute_input":"2024-04-21T20:06:40.322524Z","iopub.status.idle":"2024-04-21T20:06:41.688522Z","shell.execute_reply.started":"2024-04-21T20:06:40.322481Z","shell.execute_reply":"2024-04-21T20:06:41.687680Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Selected Arms: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\nTotal Reward: 100\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CV VALIDATION","metadata":{}},{"cell_type":"code","source":"def cross_validate_bandits(dataset, num_arms, num_rounds, num_folds=5, epsilon=0.5):\n    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n    results = {\n        'epsilon_greedy': [],\n        'thompson_sampling': [],\n        'linear_greedy': []\n    }\n\n    fold_index = 0\n    for train_index, _ in kf.split(dataset):\n        train_data = dataset.iloc[train_index]\n\n        # Epsilon Greedy\n        _, _, _, _, epsilon_rewards = epsilon_greedy_bandit(train_data, num_arms, epsilon, num_rounds)\n        results['epsilon_greedy'].append((fold_index, epsilon_rewards))\n        \n        # Thompson Sampling\n        _, _, thompson_rewards = thompson_sampling_bandit(train_data, num_arms, num_rounds)\n        results['thompson_sampling'].append((fold_index, thompson_rewards))\n        \n        # Linear Greedy\n        _, linear_rewards = linear_greedy_bandit(train_data, num_arms, num_rounds)\n        results['linear_greedy'].append((fold_index, linear_rewards))\n        \n        # Linear Greedy With Exploration\n        _, linear_epsilon_rewards = linear_greedy_bandit_epsilon(train_data, num_arms,epsilon, num_rounds)\n        results['linear_greedy'].append((fold_index, linear_epsilon_rewards))\n\n        fold_index += 1\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:41.689867Z","iopub.execute_input":"2024-04-21T20:06:41.690528Z","iopub.status.idle":"2024-04-21T20:06:41.700493Z","shell.execute_reply.started":"2024-04-21T20:06:41.690485Z","shell.execute_reply":"2024-04-21T20:06:41.699623Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"result + plot function","metadata":{}},{"cell_type":"code","source":"\ndef analyze_results(results):\n    for key, value in results.items():\n        print(f\"{key}: Mean Reward = {np.mean(value):.2f}, Std Dev = {np.std(value):.2f}\")\n\ndef plot_results(results):\n    plt.figure(figsize=(12, 8))\n    max_folds = 0  # Variable to track the maximum number of folds encountered\n\n    for policy, data in results.items():\n        if data:  # Check if data is not empty\n            folds, rewards = zip(*data)  # Unpack fold indices and rewards\n            plt.plot(folds, rewards, marker='o', label=policy)\n            max_folds = max(max_folds, max(folds) + 1)  # Update max_folds if current is greater\n\n    plt.title('Rewards by Fold for Different Bandit Policies')\n    plt.xlabel('Fold Index')\n    plt.ylabel('Total Rewards')\n    plt.xticks(range(max_folds))  # Use max_folds to set x-axis ticks\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:41.701809Z","iopub.execute_input":"2024-04-21T20:06:41.702218Z","iopub.status.idle":"2024-04-21T20:06:41.716160Z","shell.execute_reply.started":"2024-04-21T20:06:41.702188Z","shell.execute_reply":"2024-04-21T20:06:41.714857Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# Usage\nnum_arms = len(predf['match_id'].unique())\nnum_rounds = 10000  # Adjust this as necessary based on your scenario\n\n# Assuming a mock dataset and parameters for the demonstration\n# num_arms = 15  # Example number of arms\n# num_rounds = 100  # Example number of rounds for each fold\n# data = {\n#    'match_id': np.random.randint(0, num_arms, 1000),\n#    'response': np.random.randint(0, 2, 1000),  # Binary rewards as an example\n#    'similarity_score': np.random.random(1000)  # Example feature for linear regression\n#}\n#dataset = pd.DataFrame(data)\n\n# Run cross-validation\nresults = cross_validate_bandits(predf, num_arms, num_rounds)\nanalyze_results(results)\nplot_results(results)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:06:41.721428Z","iopub.execute_input":"2024-04-21T20:06:41.721783Z","iopub.status.idle":"2024-04-21T20:10:26.094708Z","shell.execute_reply.started":"2024-04-21T20:06:41.721754Z","shell.execute_reply":"2024-04-21T20:10:26.091548Z"},"trusted":true},"execution_count":76,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[76], line 16\u001b[0m\n\u001b[1;32m      3\u001b[0m num_rounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m  \u001b[38;5;66;03m# Adjust this as necessary based on your scenario\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming a mock dataset and parameters for the demonstration\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# num_arms = 15  # Example number of arms\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# num_rounds = 100  # Example number of rounds for each fold\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Run cross-validation\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_bandits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_arms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m analyze_results(results)\n\u001b[1;32m     18\u001b[0m plot_results(results)\n","Cell \u001b[0;32mIn[74], line 22\u001b[0m, in \u001b[0;36mcross_validate_bandits\u001b[0;34m(dataset, num_arms, num_rounds, num_folds, epsilon)\u001b[0m\n\u001b[1;32m     19\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthompson_sampling\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend((fold_index, thompson_rewards))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Linear Greedy\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m _, linear_rewards \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_greedy_bandit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_arms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear_greedy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend((fold_index, linear_rewards))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Linear Greedy With Exploration\u001b[39;00m\n","Cell \u001b[0;32mIn[59], line 23\u001b[0m, in \u001b[0;36mlinear_greedy_bandit\u001b[0;34m(dataset, num_arms, num_rounds)\u001b[0m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(training_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity_score\u001b[39m\u001b[38;5;124m'\u001b[39m]], training_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_rounds):\n\u001b[0;32m---> 23\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msimilarity_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_reward\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Choose the arm with the highest predicted reward\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_base.py:354\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_base.py:338\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    335\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    337\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/extmath.py:192\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 192\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/sparse/_base.py:1461\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[0;32m-> 1461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array type?\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \n\u001b[1;32m   1464\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"plot_results(results[0]+results[1]+result[3])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T20:10:26.096459Z","iopub.status.idle":"2024-04-21T20:10:26.097253Z","shell.execute_reply.started":"2024-04-21T20:10:26.096987Z","shell.execute_reply":"2024-04-21T20:10:26.097007Z"},"trusted":true},"execution_count":null,"outputs":[]}]}